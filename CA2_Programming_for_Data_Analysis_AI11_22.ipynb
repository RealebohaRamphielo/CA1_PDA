{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealebohaRamphielo/CA1_PDA/blob/main/CA2_Programming_for_Data_Analysis_AI11_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcyWEToIFQIF"
      },
      "source": [
        "<h1><b>Realeboha Raymond Ramphielo (10622234)</b></h1>\n",
        "\n",
        "<h3><i> B9AI108 Programming For Data Analysis B9AI108_2223_TMD1S </h3>\n",
        "<h3> CA 2 </i></h3>\n",
        "\n",
        "<a>[link text](https://colab.research.google.com/drive/1XIZa4PnihdmvbuFt9s89LH5AF3aYZIFr?usp=sharing)</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzRU3vnhrTPc"
      },
      "source": [
        "## **Intoduction**\n",
        "<p align=justify> Job scraping is the application of web scraping to employment. Users can easily collect employment information and build a meaningful job database using this automated online data extraction technique. There are several websites to fetch job data, these range from big job boards like <i>Irishjobs.ie</i> and the likes, right down to individual companies’ career portals. Jobs scraping involves gathering information regarding jobs and downloading it into structured and usable formats, like CSV, that can be used for analysis (Gangadhara Reddy and Viswanath, 2022). An obvious advantage to job scraping is probably data relevancy and timeliness. I will capture the HTML text using the standard Requests and Beautiful Soup configurations, and then convert it to a Beautiful Soup object to simply parse through it and retrieve the data points. I plan to scrap the Career Junction website (South African). From the website, I will scrap the Job title, copany, location, salary, day of posting, day of expiry, and a link to the job. </p>  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Lsgwq6HBDB"
      },
      "source": [
        "## Libarary intallations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb1fYUPb_eB7",
        "outputId": "e6322260-6d3b-439d-d8dd-fdaba44a98da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n"
          ]
        }
      ],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaNrME8M_irW",
        "outputId": "dce3af39-5918-4c40-e7ca-268300e0cf4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e01rEeoS_35",
        "outputId": "b94201ee-076d-44c1-ebbf-889ca21d326f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting strings\n",
            "  Downloading strings-0.1.2.tar.gz (2.2 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/bf/25/472d34792ee3816edcab999b5c00ce5e468ebd928ab5eff77f2a6738e37a/strings-0.1.2.tar.gz#sha256=8398e184ccee0900772443179554dfde157b6472a5a18c4dc68fff10de8126e7 (from https://pypi.org/simple/strings/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading strings-0.1.1.tar.gz (2.2 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/9c/c7/032ed62ca1a4b2cb299c9538d3edb4f5e7e3390dbf6b8b287c1d6534fb5c/strings-0.1.1.tar.gz#sha256=bbb79cb4aaee367f1ccd7c942c7b3929e80fe19d48648e654b0217083ae348cc (from https://pypi.org/simple/strings/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement strings (from versions: 0.1.1, 0.1.2)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for strings\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "pip install strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9QgCi_LPa4b",
        "outputId": "fef2494c-b927-4b15-9c8b-3d242376dc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.7.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 54.4 MB/s \n",
            "\u001b[?25hCollecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.8/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.4 h11-0.14.0 outcome-1.2.0 selenium-4.7.0 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.13 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ehHDOAutHXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1d39a6-11f3-4d3e-e285-27d248eb0bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from datetime import datetime, date, timedelta \n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdHx1dJR47i8"
      },
      "source": [
        "## **Steps**\n",
        "<ol>\n",
        "<li>Getting the url</li>\n",
        "<li>Scaling the salary</li>\n",
        "<li>Maing the soup</li>\n",
        "<li>Creating the dataframe and csv</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRw6Wd8rkmol"
      },
      "source": [
        "### ***Getting the url*** \n",
        "<p align=justify> The get_url function will accept two string parameters; job and location, location is set at default value of 0 which translates to no location. Within this function is a dictionary variable, locations. Locations will convert/ encode the second parameter into a usable location code by pointing at the location's value in the locations deictionary. After encoding the location, the next step is to 'plug' the desired job title and encoded location into the ural and create a url that will be returned by the function. In a case where the location is not defined, a KeyValueError will be raised by the function and an error message will be returned. </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xpm-xKLhr1Qp"
      },
      "outputs": [],
      "source": [
        "def get_url(job, location = 0):\n",
        "  \n",
        "  '''This function sets up the search url from the user defines job and location,\n",
        "    default location will be 0'''\n",
        "\n",
        "  #When no location is specified, default location = 0, i.e. the search will not\n",
        "  # have any location restrictions\n",
        "\n",
        "  locations = {'Gauteng':'2747', 'Western Cape':'16149', 'KwaZulu-Natal':'13131',\\\n",
        "              'Eastern Cape':'2', 'Free State':'1782', 'Mpumalanga':'14867',\\\n",
        "              'Limpopo':'14594', 'North West':'15372', 'Northern Cape':'15837',\\\n",
        "              'International':'1000001', 'Working From Home':'100000'}\n",
        "\n",
        "  #above is the locations dictionary that will encode the location from a normal\n",
        "  #word search to an 'int' search\n",
        "  \n",
        "  error_message = 'No access to location, please revise'\n",
        "  \n",
        "  try:\n",
        "    if location != 0:                    #encode the location\n",
        "      location = locations[location]\n",
        "    gen_url = \"https://www.careerjunction.co.za/jobs/results?keywords={}&autosuggestEndpoint=%2Fautosuggest&location={}&category=&btnSubmit=+\"\n",
        "    search_url = gen_url.format(job, location)\n",
        "    \n",
        "    return search_url\n",
        "  \n",
        "  except KeyError:\n",
        "    return error_message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZTFv6xDrXq-"
      },
      "source": [
        "###***Scaling the salary***\n",
        "<p align=justify> The salary_convert funtion will take one string parameter. The purpose of this function is to scale the salary to monthly rates. It will first strip the string off the 'R' which denotes the ZAR (South AFrican Rand), then strip off any white split the string using white space. Following the split, we will take the first element (element at index 0) and follow this by splitting it using the period (dot) character and assign to a_string variable the first element from the resulting split. Some figures are comma separated, thus the second step will be to get remove any commas from a_string and covert the variable to a float and multiply it by a scaling factor to calculate a monthly salary, the scaling factors are as follows:\n",
        "<ul>\n",
        "<li>160 for hourly pay</li>\n",
        "<li>20 for daily pay</li>\n",
        "<li>4 for weekly pay</li>\n",
        "<li>2 for fortnight pay</li>\n",
        "<li>1 for monthly pay</li>\n",
        "<li>1/12 for annual pay</li>\n",
        "</ul>\n",
        "The function will return the scaled salary after multiplying it by the scaling factor. In instances where the salary is not mentioned/ disclosed (or when no figure is given), the figure will return a NaN value (missing value) from Numpy.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TMnhosayTEgX"
      },
      "outputs": [],
      "source": [
        "def salary_convert(b_string):\n",
        "\n",
        "  ''' The function will convert help extract salaries and scales them to a \n",
        "    monthly value'''\n",
        "\n",
        "  if 'per hour' in b_string:           #hourly rate\n",
        "    a_string = b_string.strip('R').strip().split()[0].split('.')[0] \n",
        "    #strip the 'R' and any possible space then split b_string by 'space' and \n",
        "    #is assigned 0 index value, then splits that new string by 'dot' and is \n",
        "    #assigned value at index 0\n",
        "    #eliminates the 'comma' in a_string by replacing it with 'no space'\n",
        "    \n",
        "    a_string = float(a_string.replace(',', '')) * 160\n",
        "    #eliminates the 'comma' in a_string by replacing it with 'no space' then\n",
        "    #multiples the float a_string by the hours that make up a month\n",
        "\n",
        "    #the code will generally be the same, only change is the multiplying factor\n",
        "\n",
        "  elif 'per day' in b_string:         #daily rate\n",
        "    a_string = b_string.strip('R').strip().split()[0].split('.')[0]\n",
        "    a_string = float(a_string.replace(',', '')) * 20\n",
        "\n",
        "  elif 'per week' in b_string:         #weekly rate\n",
        "    a_string = b_string.strip('R').split()[0].split('.')[0]\n",
        "    a_string = float(a_string.replace(',', '')) * 4\n",
        "\n",
        "  elif 'per fort' in b_string:         #fortnight rate\n",
        "    a_string = b_string.strip('R').strip().split()[0].split('.')[0]\n",
        "    a_string = float(a_string.replace(',', '')) * 2\n",
        "\n",
        "  elif 'per month' in b_string:        #monthly rate\n",
        "    a_string = b_string.strip('R').strip().split()[0].split('.')[0]\n",
        "    a_string = float(a_string.replace(',', ''))\n",
        "\n",
        "  elif 'per year' in b_string:       #yearly rate\n",
        "    a_string = b_string.strip('R').strip().split()[0].split('.')[0]\n",
        "    a_string = float(a_string.replace(',', '')) / 12\n",
        "\n",
        "  else:    #Undisclosed salaries\n",
        "    a_string = np.NaN\n",
        "\n",
        "  return a_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwT4L4H-vai8"
      },
      "source": [
        "### ***Making the Soup***\n",
        "<p align=justify>\n",
        "The make_soup function will take job (string) and location (string, but has a default 0 value) parameters. The first step is to pass these parameters to the get_url function and create the url. This will be followed by adding the page number to the url and creating a request. The request content; response response will be be passed through Beautiful Soup whuch will help us create the Soup variable pasta. Jobs will be set as the jobs container part of the pasta and individual job cards will be stored as j_cards. We will the loop over the j_cards list, every job card will have its dictionary that will later be added to an empty list of job collection following each iteration. A job title, company, location, salary, posting date, expiry date and link will all be added as Key and value pairs to the individaul job dictionary. Monthly salary will be calculated by calling the salary_convert function and added to the dictionary. The duration of the ad in days from day of posting to expiry date will be calculated within the for loop by subtracting the posting date from the expiry date. Also calculated within the for loop, the days left before the ad expires will be the difference between the expiry date and the day of exctraction  (scraping). Both these will be added as individual key-value pairs to the dictionary. This process will continue until the needed information from each jobs on one page is collected, the process will the continue for every page until the last page, which is usually a maximum of 30 for this website. make_soup will return job_collection, a list of dictionaries of every scraped job.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vBYIV2kVXgc5"
      },
      "outputs": [],
      "source": [
        "def make_soup(job, location=0):\n",
        "  \n",
        "  '''The function creates a response from the created by get_url, then scraps \n",
        "    the actual data from the website'''\n",
        "\n",
        "  gen_url = get_url(job, location)    #defines the website that will be scraped\n",
        "  job_collection = []    #empty list to contain all the extracted job attributes \n",
        "\n",
        "  for i in range(1,30):\n",
        "    search_page = f\"&page={str(i)}\"          #this is the start page\n",
        "    url = gen_url + search_page             #add a page to the url\n",
        "    the_response = requests.get(url)  \n",
        "\n",
        "    pasta = BeautifulSoup(the_response.content, 'html.parser') #create the soup\n",
        "    jobs = pasta.find('div', class_=\"two-thirds\")          #location of the jobs on the page\n",
        "    try:\n",
        "      j_cards = jobs.find_all('div', class_=\"job-result\")    #collection of the jobs on the page\n",
        "    \n",
        "      for j_card in j_cards:  #looping over the job cards list to extract features of each job\n",
        "        a_job = {}            #dictionary to hold individual job information\n",
        "        \n",
        "        prim_link = \"https://www.careerjunction.co.za\"\n",
        "        j_today = date.today()\n",
        "        j_title = j_card.find('h2')\n",
        "        \n",
        "        a_job['Job Title'] = j_title.text.strip()\n",
        "        #company_name = j_card.find('h3')\n",
        "        if j_card.find('h3') is not None:\n",
        "          a_job['Company'] = j_card.find('h3').text.strip()\n",
        "        a_job['Location'] = j_card.find('li', class_=\"location\").text.strip()\n",
        "        a_job['Job Type'] = j_card.find('li', class_=\"position\").text.strip()\n",
        "\n",
        "        a_job['Salary'] = j_card.find('li', class_=\"salary\").text.strip()\n",
        "        a_job['Monthly Salary'] = salary_convert(a_job['Salary'])\n",
        "\n",
        "        a_job['Posting Date'] = j_card.find('li', class_=\"updated-time\").text\\\n",
        "        .strip('Posted').strip()\n",
        "\n",
        "        j_expiry = j_card.find('li', class_=\"expires\").text.split()[2]\n",
        "        try:\n",
        "          ini_exp = j_today + timedelta(days=int(j_expiry))\n",
        "        except ValueError:\n",
        "          ini_exp = j_today\n",
        "        a_job['Expiry Date'] = ini_exp.strftime('%d %b %Y')\n",
        "        j_duration = pd.to_datetime(a_job['Expiry Date'])-pd.to_datetime(a_job['Posting Date'])\n",
        "        j_toExpire = pd.to_datetime(a_job['Expiry Date'])-pd.to_datetime(j_today.strftime('%d %b %Y'))\n",
        "        a_job['Ad Duration (Days)'] = int(str(j_duration).split()[0])\n",
        "        a_job['Days before expiry'] = int(str(j_toExpire).split()[0])\n",
        "\n",
        "        a_job['Link'] = prim_link + j_title.find('a').get('href')\n",
        "\n",
        "        job_collection.append(a_job) \n",
        "        #adds the single jobs dictionary to the jobs collection list, feature names are the keys\n",
        "    except AttributeError:\n",
        "      break    #this break the function if it has run out of pages to scrap\n",
        "\n",
        "  return job_collection    #returns jobs list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3b8WIqevfhk"
      },
      "source": [
        "### ***Creating a data frame and CSV file***\n",
        "\n",
        "<p align=justify>\n",
        "The last function, main_jobs, will take two parameters, job and location which has a default value of zero. This function calls make_soup and passes the arguments. The resulting list of dictionaries will be converted to a pandas dataframe, then the columns will be rearranged for easier browsing following which, a CSV file will be written from the resulting dataframe. The function also returns this dataframe. \n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PNx6z5IUfyTB"
      },
      "outputs": [],
      "source": [
        "def main_jobs(job, location=0):\n",
        "\n",
        "  '''Runs make_soup functions then creates a pandas dataframe that will be\n",
        "    converted into a csv file'''\n",
        "    \n",
        "  cols_ord = ['Job Title', 'Location', 'Job Type', 'Company', 'Salary', \\\n",
        "              'Monthly Salary', 'Posting Date', 'Expiry Date', \\\n",
        "              'Ad Duration (Days)','Days before expiry', 'Link']\n",
        "\n",
        "  j_data = make_soup(job, location)  #defines a list of dictionaries\n",
        "  df = pd.DataFrame(j_data)          #coverts the list above to a dataframe\n",
        "  df= df[cols_ord]                   #reorders the columns\n",
        "  df.to_csv('jobs_data.csv')   #creates a jobs_data csv file from the dataframe\n",
        "\n",
        "  return df "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFm7slOrvnwO"
      },
      "source": [
        "### ***Some tests***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6CSM2gCjZA2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "ab9389f9-1dc0-4101-ca69-80c2a0136e61"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f7795f912670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msome_some\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gauteng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-eabf6751666a>\u001b[0m in \u001b[0;36mmain_jobs\u001b[0;34m(job, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m               'Ad Duration (Days)','Days before expiry', 'Link']\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mj_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#defines a list of dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_data\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m#coverts the list above to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_ord\u001b[0m\u001b[0;34m]\u001b[0m                   \u001b[0;31m#reorders the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b68be1f6ce2a>\u001b[0m in \u001b[0;36mmake_soup\u001b[0;34m(job, location)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msearch_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"&page={str(i)}\"\u001b[0m          \u001b[0;31m#this is the start page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msearch_page\u001b[0m             \u001b[0;31m#add a page to the url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mthe_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpasta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#create the soup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "some_some = main_jobs('data', 'Gauteng')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDxLfEs3nWe1"
      },
      "outputs": [],
      "source": [
        "print(some_some['Ad Duration (Days)'].max(), some_some['Ad Duration (Days)']\\\n",
        "      .min(), round(some_some['Ad Duration (Days)'].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSv2xfHPxyVB"
      },
      "outputs": [],
      "source": [
        "# #p_play = 'R ds dsdR'\n",
        "# #p_play2 = p_play.strip('R')\n",
        "# #p_play2\n",
        "\n",
        "# ttttt = '400.00 - 300'.split()[0].split('.')[0]\n",
        "# print(ttttt)\n",
        "# tttttd = '400,00 - 300'.split()[0].split('.')[0]\n",
        "# print(tttttd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "RCXX65vKLvr0",
        "outputId": "2332e4b0-89fb-4d8e-b4fb-58d19d9728ea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d68b81df302c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mcococ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"&page={str(i)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mgen_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_url3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcococ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mresp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#print(resp, resp.reason)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#from numpy.lib.shape_base import dsplit\n",
        "li = []\n",
        "for i in range(1,3):\n",
        "  gen_url3 = \"https://www.careerjunction.co.za/jobs/results?keywords=data&autosuggestEndpoint=%2fautosuggest&location=2747&category=&btnSubmit=+\"\n",
        "  #url1 = get_url('data', 'Limpopo')\n",
        "  cococ = f\"&page={str(i)}\"\n",
        "  gen_url = gen_url3 + cococ\n",
        "  response = requests.get(gen_url)\n",
        "  resp=response.content\n",
        "  #print(resp, resp.reason)\n",
        "  #print(gen_url)\n",
        "  #print(url1)\n",
        "  #resp.status_code\n",
        "  pasta = BeautifulSoup(resp, 'html.parser')\n",
        "  jobs = pasta.find('div', class_=\"two-thirds\")\n",
        "  j_cards = jobs.find_all('div', class_=\"job-result\")\n",
        "  #j_cards.pop(5)\n",
        "  print(len(j_cards))\n",
        "  #j_cards\n",
        "  #li = []\n",
        "  for j_card in j_cards:\n",
        "    j_today = date.today()\n",
        "    a_job = {}\n",
        "    titleofjob = j_card.find('h2')\n",
        "    a_job['Job Title'] = (titleofjob.text.strip())\n",
        "  #  a_job['Company'] = (j_card.find('h3').text.strip())\n",
        "    a_job['Location'] = (j_card.find('li', class_=\"location\").text.strip())\n",
        "    a_job['Job Type'] = (j_card.find('li', class_=\"position\").text.strip())\n",
        "    a_job['Salary'] = (j_card.find('li', class_=\"salary\").text.strip())\n",
        "    a_job['Monthly Salary'] = salary_convert(a_job['Salary'])\n",
        "    \n",
        "    a_job['Posting date'] = (j_card.find('li', class_=\"updated-time\").text.strip('Posted').strip())\n",
        "    j_expiry = j_card.find('li', class_=\"expires\").text.split()[2]\n",
        "    if j_expiry != 'today':\n",
        "      ini_exp = j_today + timedelta(days=int(j_expiry))\n",
        "      a_job['Expiry date'] = ini_exp.strftime('%d %b %Y')\n",
        "    else:\n",
        "      a_job['Expiry date'] = j_today.strftime('%d %b %Y')\n",
        "    #a_job['Job URL'] = (j_card.find('h2').text.strip())\n",
        "    duration1 = pd.to_datetime(a_job['Expiry date']) - pd.to_datetime(a_job['Posting date'])\n",
        "    duration2 = pd.to_datetime(a_job['Expiry date']) - pd.to_datetime(j_today.strftime('%d %b %Y'))\n",
        "    #a_job['j_title'] = (j_card.find('h2').text.strip())\n",
        "    a_job['sahdis'] = int(str(duration1).split()[0])\n",
        "    a_job['sahdis2'] = int(str(duration2).split()[0])\n",
        "    a_job['Link']  = 'https://www.careerjunction.co.za'+titleofjob.find('a').get('href')\n",
        "\n",
        "    li.append(a_job)\n",
        "\n",
        "  #two-way step in accessing an embedded feature, find outer tag and assign it\n",
        "  #then use asigned_varaible.attrs['some_tag'] to locate the embedded feature\n",
        "  #eg -> var = j_card.find('h2') followed by feature = var.attrs['a'] \n",
        "\n",
        "  #convert final list of dictionaries to a pandas dataframe then use to_csv after\n",
        "  #df = pd.DataFrame(jobs) followed by df.to_csv('file_name.csv')\n",
        "\n",
        "  #len(li)\n",
        "  #li[3]\n",
        "#li\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2VnA_SSAtLY"
      },
      "outputs": [],
      "source": [
        "# reew = 'R58,300'.strip(',').strip('R')\n",
        "# print(reew)\n",
        "# reew = ''.join(item for item in reew if item.isalnum())\n",
        "# reew\n",
        "# fesad = 'R58,30000'\n",
        "# print(float(fesad.replace(',', '').strip('R')))  # ValueError: invalid literal for int() with base 10: '58300.00'\n",
        "# weeeer = '400.00'.split('.')\n",
        "# weeeer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz8ZAj6Y26iQ"
      },
      "outputs": [],
      "source": [
        "# dfdf = pd.DataFrame(li)\n",
        "# dfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-3vL00l8gRk"
      },
      "outputs": [],
      "source": [
        "# if 'per hour' in a_job['Salary']:\n",
        "#   a_job['Montly Salary'] = a_job['Salary'].strip(',').split()[0]\n",
        "#       a_job['Montly Salary'] = a_job['Montly Salary'].split('.')[0]\n",
        "#       a_job['Montly Salary'] = int(''.join(jk for jk in a_job['Montly Salary'] if jk.isalnum()))* 160\n",
        "#     elif 'per day' in a_job['Salary']:\n",
        "#       a_job['Montly Salary'] = a_job['Salary'].strip(',').split()[0]\n",
        "#       a_job['Montly Salary'] = int(''.join(jk for jk in a_job['Montly Salary'] if jk.isalnum()))* 20\n",
        "#     elif 'per week' in a_job['Salary']:\n",
        "#       a_job['Montly Salary'] = a_job['Salary'].strip(',').split()[0]\n",
        "#       a_job['Montly Salary'] = int(''.join(jk for jk in a_job['Montly Salary'] if jk.isalnum()))*4\n",
        "#     elif 'per fort' in a_job['Salary']:\n",
        "#       a_job['Montly Salary'] = a_job['Salary'].strip(',').split()[0]\n",
        "#       a_job['Montly Salary'] = int(''.join(jk for jk in a_job['Montly Salary'] if jk.isalnum()))*2\n",
        "#     elif 'per month' in a_job['Salary']:\n",
        "#       a_job['Montly Salary'] = a_job['Salary'].strip(',').split()[0]\n",
        "#       a_job['Montly Salary'] = int(''.join(jk for jk in a_job['Montly Salary'] if jk.isalnum()))\n",
        "#     elif 'per year' in a_job['Salary']:\n",
        "#       a_job['Montly Salary'] = a_job['Salary'].strip(',').split()[0]\n",
        "#       a_job['Montly Salary'] = int(''.join(jk for jk in a_job['Montly Salary'] if jk.isalnum()))/12\n",
        "#     else:\n",
        "#       a_job['Montly Salary'] = np.NaN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP0wDLB7Hb1H"
      },
      "outputs": [],
      "source": [
        "gen_url100 = \"https://www.careerjunction.co.za/jobs/results?keywords=data&autosuggestEndpoint=%2fautosuggest&location=2747&category=&btnSubmit=+&page=2898\"\n",
        "resp100 = requests.get(gen_url100)\n",
        "print(resp100, resp100.reason) \n",
        "print(resp100.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_M8qSBYQ2Mt"
      },
      "outputs": [],
      "source": [
        "li = []\n",
        "for j_card in j_cards:\n",
        "  j_today = date.today()\n",
        "  a_job = {}\n",
        "  a_job['Job Title'] = (j_card.find('h2').text.strip())\n",
        "  a_job['Company'] = (j_card.find('h3').text.strip())\n",
        "  a_job['Location'] = (j_card.find('li', class_=\"location\").text.strip())\n",
        "  a_job['Job Type'] = (j_card.find('li', class_=\"position\").text.strip())\n",
        "  a_job['Salary'] = (j_card.find('li', class_=\"salary\").text.strip('R').strip())\n",
        "  a_job['Posting date'] = (j_card.find('li', class_=\"updated-time\").text.strip('Posted').strip())\n",
        "  j_expiry = j_card.find('li', class_=\"expires\").text.split()[2]\n",
        "  if j_expiry != 'today':\n",
        "    ini_exp = j_today + timedelta(days=int(j_expiry))\n",
        "    a_job['Expiry date'] = ini_exp.strftime('%d %b %Y')\n",
        "  else:\n",
        "    a_job['Expiry date'] = j_today.strftime('%d %b %Y')\n",
        "  a_job['Duration'] = pd.to_datetime(a_job['Expiry date']) - pd.to_datetime(a_job['Posting date'])\n",
        "  #a_job['Job URL'] = (j_card.find('h2').text.strip())\n",
        "  #a_job['j_title'] = (j_card.find('h2').text.strip())\n",
        "\n",
        "  li.append(a_job)\n",
        "\n",
        "#two-way step in accessing an embedded feature, find outer tag and assign it\n",
        "#then use asigned_varaible.attrs['some_tag'] to locate the embedded feature\n",
        "#eg -> var = j_card.find('h2') followed by feature = var.attrs['a'] \n",
        "\n",
        "#convert final list of dictionaries to a pandas dataframe then use to_csv after\n",
        "#df = pd.DataFrame(jobs) followed by df.to_csv('file_name.csv')\n",
        "\n",
        "len(li)\n",
        "li[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGukwUZq3EsZ"
      },
      "outputs": [],
      "source": [
        "#gen_url will change to url when get_url function is finally up and running\n",
        "tsamaea = jobs.find('ul', {'id':'pagination'})\n",
        "gen_url2 = tsamaea.find('a', class_=\"alt\")\n",
        "semate = gen_url[0]\n",
        "print(gen_url2)\n",
        "print(semate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXjJ9wwQiU2k"
      },
      "outputs": [],
      "source": [
        "rea_today = datetime.now()#.strftime('%d %b %Y')\n",
        "rea_today = rea_today + timedelta(days=1)\n",
        "rea_today.strftime('%d %b %Y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7f3iiIYvwjn"
      },
      "source": [
        "### Attempting wrapping inside a class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUrHMP1Xqtvm"
      },
      "outputs": [],
      "source": [
        "class JobScraping():\n",
        "  def __init__(self, l):\n",
        "    l = self.l\n",
        "\n",
        "  def get_url(self, j, l):\n",
        "    pass\n",
        "\n",
        "  def sal_set(self, s):\n",
        "    pass\n",
        "\n",
        "  def soup_set(self, j, l):\n",
        "    pass\n",
        "\n",
        "  def main_run(sefl, j, l):\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "H8Lsgwq6HBDB",
        "qRw6Wd8rkmol",
        "AZTFv6xDrXq-",
        "fwT4L4H-vai8",
        "Z3b8WIqevfhk"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNgppqCMzcpk1YAsm0zxAF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}